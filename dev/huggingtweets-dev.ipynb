{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oXeYEzBG7g0H"
      },
      "source": [
        "# HuggingTweets - Tweet Generation with Huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nZuE848q7g0I"
      },
      "source": [
        "*Disclaimer: this project is not to be used to publish any false generated information but to perform research on Natural Language Generation (NLG).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "668-beiK7g0J"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/borisdayma/huggingtweets/blob/master/huggingtweets.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre colab\n",
        "\n",
        "\n",
        "\n",
        "1. Download csvfilter.py\n",
        "2. Download the discord messages for the person as csv\n",
        "3. merge the csv's together\n",
        "4. run csvfilter.py and follow instructions\n",
        "5. once it asks for content and number removal go to edit-csv and remove the first columm and row\n",
        "6. when it asks for whitename removal execute the powershell script then press return on the script\n",
        "7. the ouput will be the fully filtered csv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wODF0Bx27g0K"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jxRDBrFi7g0L"
      },
      "outputs": [],
      "source": [
        "# install required libraries are not installed\n",
        "!pip install torch -qq\n",
        "!pip install transformers -qq\n",
        "!pip install wandb -qq\n",
        "!pip install tweepy -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4IRQjZw37g0P"
      },
      "outputs": [],
      "source": [
        "# HuggingFace scripts for fine-tuning models and language generation\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/language-modeling/run_language_modeling.py -q\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/text-generation/run_generation.py -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter\n",
        "\n",
        "filter the csv file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from array import array\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print(\"Use Py scripts to generate dataset csv\")\n",
        "files.upload()\n",
        "!ls\n",
        "csvanme = input(\"enter csv name\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make Dataset\n",
        "\n",
        "help me please\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "import torch\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "handle = 'JustinHughes'\n",
        "with open(csvanme, newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
        "    reader = list(reader)\n",
        "# shuffle data\n",
        "    random.shuffle(reader)\n",
        "\n",
        "# fraction of training data\n",
        "    split_train_valid = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split dataset\n",
        "    train_size = int(split_train_valid * len(reader))\n",
        "    valid_size = len(reader) - train_size\n",
        "    train_dataset, valid_dataset = torch.utils.data.random_split(reader, [train_size, valid_size]) \n",
        "\n",
        "    def make_dataset(dataset, epochs):\n",
        "        reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
        "        total_text = '<|endoftext|>'\n",
        "        reader = [t for t in dataset]\n",
        "        for _ in range(epochs):\n",
        "            random.shuffle(reader)\n",
        "            total_text += '<|endoftext|>'.join(map(str, reader)) + '<|endoftext|>'\n",
        "        return total_text\n",
        "    EPOCHS = 4\n",
        "\n",
        "    with open('{}_train.txt'.format(handle), 'w') as f:\n",
        "        data = make_dataset(train_dataset, EPOCHS)\n",
        "        f.write(data)\n",
        "\n",
        "    with open('{}_valid.txt'.format(handle), 'w') as f:\n",
        "        data = make_dataset(valid_dataset, 1)\n",
        "        f.write(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dKfJrfl57g1J"
      },
      "source": [
        "## Log and monitor training through W&B\n",
        "\n",
        "In order to check our model is training correctly and compare experiments, we are going to use the W&B integration from HuggingFace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cD3v1dDK7g1J"
      },
      "source": [
        "### API Key\n",
        "Once you've signed up, run the next cell and click on the link to get your API key and authenticate this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tDu7g4dy7g1K"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MeCgMAKo7g1N"
      },
      "source": [
        "## Fine-tuning the model\n",
        "\n",
        "HuggingFace includes the script `run_language_modeling` making it easy to fine-tune a pre-trained model.\n",
        "\n",
        "We use a pre-trained GPT-2 model and fine-tune it on our dataset.\n",
        "\n",
        "Training is automatically logged on W&B (see [documentation](https://docs.wandb.com/huggingface)). Urls are generated to visualize ongoing runs or you can just open your [dashboard](http://app.wandb.ai/).\n",
        "\n",
        "IÂ quickly tested running for several epochs and my run was showing I started overfitting after 4 epochs so this is the limit I use to fine-tune my model (takes less than 2 minutes).\n",
        "\n",
        "![](https://i.imgur.com/1uIxLFe.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fA0SYlIU7g1N"
      },
      "outputs": [],
      "source": [
        "# Associate run to a project (optional)\n",
        "%env WANDB_PROJECT=huggingtweets-dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WJQoCJV97g1Q"
      },
      "source": [
        "We use HuggingFace script `run_language_modeling.py` to fine-tune our model (see [doc](https://huggingface.co/transformers/)).\n",
        "\n",
        "*Note: epochs are built into the dataset*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "X4LWV56z7g1Q"
      },
      "outputs": [],
      "source": [
        "!python run_language_modeling.py \\\n",
        "    --output_dir=output/$handle \\\n",
        "    --overwrite_output_dir \\\n",
        "    --overwrite_cache \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=gpt2 \\\n",
        "    --do_train --train_data_file=$handle\\_train.txt \\\n",
        "    --do_eval --eval_data_file=$handle\\_valid.txt \\\n",
        "    --evaluate_during_training \\\n",
        "    --eval_steps 20 \\\n",
        "    --logging_steps 20 \\\n",
        "    --per_gpu_train_batch_size 1 \\\n",
        "    --num_train_epochs 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "viSAJ7EE7g1T"
      },
      "source": [
        "## Let's test our trained model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ffHmhI9P7g1T"
      },
      "source": [
        "We test our model on a few sample sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uQRNMedK7g1T"
      },
      "outputs": [],
      "source": [
        "SENTENCES = [\"I think that\",\n",
        "             \"I like\",\n",
        "             \"I don't like\",\n",
        "             \"I want\",\n",
        "             \"My dream is\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ImkNghlH7g1V"
      },
      "source": [
        "We use HuggingFace script `run_generation.py` to generate sentences (see [doc](https://huggingface.co/transformers/))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dK-R3bPP7g1W"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "seed = random.randint(0, 2**32-1)\n",
        "seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EkD5CRkn7g1Y"
      },
      "outputs": [],
      "source": [
        "examples = []\n",
        "num_return_sequences = 5\n",
        "\n",
        "for start in SENTENCES:\n",
        "    val = !python run_generation.py \\\n",
        "        --model_type gpt2 \\\n",
        "        --model_name_or_path output/$handle \\\n",
        "        --length 160 \\\n",
        "        --num_return_sequences $num_return_sequences \\\n",
        "        --temperature 1 \\\n",
        "        --p 0.95 \\\n",
        "        --seed $seed \\\n",
        "        --prompt {'\"<|endoftext|>' + start + '\"'}\n",
        "    generated = [val[-1-2*k] for k in range(num_return_sequences)[::-1]]\n",
        "    print(f'\\nStart of sentence: {start}')\n",
        "    for i, g in enumerate(generated):\n",
        "        g = g.replace('<|endoftext|>', '')\n",
        "        print(f'* Generated #{i+1}: {g}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n6kHI7_D7g1g"
      },
      "source": [
        "## About\n",
        "\n",
        "*Built by Boris Dayma*\n",
        "\n",
        "[![Follow](https://img.shields.io/twitter/follow/borisdayma?style=social)](https://twitter.com/intent/follow?screen_name=borisdayma)\n",
        "\n",
        "My main goals with this project are:\n",
        "* to experiment with how to train, deploy and maintain neural networks in production ;\n",
        "* to make AI accessible to everyone ;\n",
        "* to have fun!\n",
        "\n",
        "For more details, visit the project repository.\n",
        "\n",
        "[![GitHub stars](https://img.shields.io/github/stars/borisdayma/huggingtweets?style=social)](https://github.com/borisdayma/huggingtweets)\n",
        "\n",
        "**Disclaimer: this project is not to be used to publish any false generated information but to perform research on Natural Language Generation.**\n",
        "\n",
        "## Resources\n",
        "\n",
        "* [Explore the W&B report](https://app.wandb.ai/wandb/huggingtweets/reports/HuggingTweets-Train-a-model-to-generate-tweets--VmlldzoxMTY5MjI) to understand how the model works\n",
        "* [HuggingFace and W&B integration documentation](https://docs.wandb.com/library/integrations/huggingface)\n",
        "\n",
        "## Got questions about W&B?\n",
        "\n",
        "If you have any questions about using W&B to track your model performance and predictions, please reach out to the [slack community](http://bit.ly/wandb-forum)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "huggingtweets-dev.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
